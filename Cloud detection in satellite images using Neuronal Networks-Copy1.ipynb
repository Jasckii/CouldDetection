{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train this CNN I have used a database with more than 31,500 images from 45 classes and have variety to wether, location and distance. \n",
    "<img src=\"ISatelitales/golf_course/golf_course_013.jpg\" width=200 height=200>\n",
    "<img src=\"ISatelitales/cloud/cloud_018.jpg\" width=200 height=200> \n",
    "<img src=\"ISatelitales/ship/ship_011.jpg\" width=200 height=200>\n",
    "\n",
    "Publication of the database:  G. Cheng, J. Han, X. Lu. Remote Sensing Image Scene Classification: Benchmark and State of the Art. Proceedings of the IEEE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\ 0\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\airplane 0\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\airport 700\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\baseball_diamond 1400\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\basketball_court 2100\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\beach 2800\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\bridge 3500\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\chaparral 4200\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\church 4900\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\circular_farmland 5600\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\cloud 6300\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\commercial_area 7000\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\dense_residential 7700\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\desert 8400\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\forest 9100\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\freeway 9800\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\golf_course 10500\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\ground_track_field 11200\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\harbor 11900\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\industrial_area 12600\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\intersection 13300\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\island 14000\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\lake 14700\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\meadow 15400\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\medium_residential 16100\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\mobile_home_park 16800\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\mountain 17500\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\overpass 18200\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\palace 18900\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\parking_lot 19600\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\railway 20300\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\railway_station 21000\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\rectangular_farmland 21700\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\river 22400\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\roundabout 23100\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\runway 23800\n",
      "F:\\Cloud-detectionusing-CNN-Baby\\ISatelitales\\sea_ice 24500\n",
      "Total images:  24636\n",
      "Cloud images:  700\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), 'ISatelitales')\n",
    "imgpath = dirname + os.sep # os.sep es = \\\n",
    "\n",
    "imag = [] #list with images \n",
    "IDcat = [] #1 is could,0 is no cloud\n",
    "IDim = [] #list of img index\n",
    "idim = 0 #img index begin with 0\n",
    "\n",
    "\n",
    "\n",
    "for ruta, carpetas, filenames in os.walk(imgpath): # path, folder and file names:\n",
    "\n",
    "    print(ruta,idim)\n",
    "    for filename in filenames: # looking at all files individually\n",
    "            \n",
    "        if ruta == imgpath +'cloud':  # if the image is in the cloud folder\n",
    "            IDim.append(idim) ; idim += 1\n",
    "            IDcat.append(1) # if the image have clouds IDcat value is 1\n",
    "            filepath = os.path.join(ruta, filename) #obtain the image direction \n",
    "            imagen = plt.imread(filepath) #obtain the image array.\n",
    "            imag.append(imagen) #save the image in images list\n",
    "        else: \n",
    "            IDim.append(idim) ; idim += 1\n",
    "            IDcat.append(0) # if the image have clouds IDcat value is 0\n",
    "            filepath = os.path.join(ruta, filename) #obtain the image direction \n",
    "            imagen = plt.imread(filepath) #obtain the image array.\n",
    "            imag.append(imagen) #save the image in images list\n",
    "print('Total images: ',idim)\n",
    "print('Cloud images: ',sum(IDcat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=IDcat\n",
    "imagenes=imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Division of the set into subsets training, validation and testing\n",
    "It is necessary to separate the dataset into 3 groups:\n",
    "* Train: will be used to train the CNN, it is the largest subset, it is 49% of the total images.\n",
    "* Test: Used to calculate the error when the CNN is being trained, it is 21% of the total images.\n",
    "* Validation: Used to validate the test score after training the CNN with a new data set, it is 30% of the total images.\n",
    "\n",
    "This dataset has 31500 images, but only 700 have clouds, 2.2%. We have an imbalanced dataset, training a CNN with this ratio is a mistake. For this reason it is necessary to modify the ratio in the trining, test and validation dataset. After many tests, the best ratios are:\n",
    "25% of images with clouds and 75% of images without clouds.\n",
    "\n",
    "* Train: 30% of images with clouds.\n",
    "* Test: 50% of images with clouds.\n",
    "* Validation: 25% of images with clouds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud-free images filtering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_proportion(dat_set_cat, dat_set_im, rat_acept):\n",
    "    Cat = [] \n",
    "    Im = []\n",
    "    con1= 0 #counter Cloud-free images\n",
    "    con2= 0 #counter cloud images\n",
    "    lim = len(dat_set_cat)\n",
    "    for i in range(lim) :\n",
    "        if dat_set_cat[i] == 0:\n",
    "            R=random.random()\n",
    "            if R < rat_acept:\n",
    "                con1 += 1\n",
    "                Im.append(dat_set_im[i])\n",
    "                Cat.append(dat_set_cat[i])\n",
    "\n",
    "        elif dat_set_cat[i] == 1:\n",
    "            con2 += 1\n",
    "            Im.append(dat_set_im[i])\n",
    "            Cat.append(dat_set_cat[i])\n",
    "\n",
    "\n",
    "    Cat = np.array(Cat)\n",
    "    Im = np.array(Im, dtype=np.uint8)\n",
    "    print ('Ratio cloud images: ',con2/(con1+con2), '%')\n",
    "    del dat_set_im; del dat_set_cat\n",
    "    \n",
    "    return Im, Cat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data set into data subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsets train-test and validation\n",
    "Im,valIm1,Cat,valCat1 = train_test_split(imagenes,cat,test_size=0.3) \n",
    "del imagenes; del cat;\n",
    "\n",
    "#subsets train test\n",
    "entrIm1,testIm1,entrCat1,testCat1 = train_test_split(Im,Cat,test_size=0.3)\n",
    "del Im; del Cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#import keras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#from keras import optimizers\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from keras.utils import to_categorical\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "#from keras import optimizers\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # 随机旋转的角度范围\n",
    "    width_shift_range=0.2,  # 随机水平移动的范围\n",
    "    height_shift_range=0.2,  # 随机垂直移动的范围\n",
    "    shear_range=0.2,  # 剪切强度\n",
    "    zoom_range=0.2,  # 随机缩放的范围\n",
    "    horizontal_flip=True,  # 随机水平翻转\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# 使用.flow_images()方法来增强图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Filtering unclouded images from subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valIm, valCat = filter_proportion(valCat1, valIm1, rat_acept=0.07)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "col = 5\n",
    "for i in range(col):\n",
    "    plt.subplot(5//col+1,col,i+1)\n",
    "    plt.imshow(valIm[i])\n",
    "    plt.title(valCat[i])\n",
    "\n",
    "print(len(valIm))\n",
    "print(len(valIm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrIm, entrCat = filter_proportion(entrCat1, entrIm1, rat_acept=0.05)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "col = 5\n",
    "for i in range(col):\n",
    "    plt.subplot(5//col+1,col,i+1)\n",
    "    plt.imshow(entrIm[i])\n",
    "    plt.title(entrCat[i])\n",
    "\n",
    "print(len(entrIm))\n",
    "print(len(entrIm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIm, testCat = filter_proportion(testCat1, testIm1, rat_acept=0.025)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "col = 5\n",
    "for i in range(col):\n",
    "    plt.subplot(5//col+1,col,i+1)\n",
    "    plt.imshow(testIm[i])\n",
    "    plt.title(testCat[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images are the same size, so the only step will be to normalize the pixel value in the arrays. This step is necessary for the best performance of the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valIm = valIm / 255.\n",
    "entrIm = entrIm / 255.\n",
    "testIm = testIm / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Develop the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight', \n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias',\n",
    "                                 shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2 = Sequential()\n",
    "modelo2.add(Conv2D(60, kernel_size=(3, 3),activation='relu',padding='same',input_shape=(256,256,3)))\n",
    "modelo2.add(MaxPooling2D((4, 4)))\n",
    "\n",
    "modelo2.add(AttentionLayer()) \n",
    "\n",
    "modelo2.add(Conv2D(120, (3, 3), activation='relu')) #padding default is valid\n",
    "modelo2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "modelo2.add(Dropout(0.5))\n",
    "modelo2.add(Conv2D(200, (3, 3), activation='relu'))\n",
    "modelo2.add(MaxPooling2D((2, 2)))\n",
    "modelo2.add(Conv2D(250, (3, 3), activation='relu'))\n",
    "\n",
    "modelo2.add(Dropout(0.5))\n",
    "modelo2.add(Flatten())\n",
    "modelo2.add(Dense(512, activation='relu'))\n",
    "modelo2.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC, PrecisionAtRecall\n",
    "\n",
    "# 精确率\n",
    "def precision(y_true, y_pred):\n",
    "    # 确保y_pred的值在0和1之间\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "# 召回率\n",
    "def recall(y_true, y_pred):\n",
    "    # 确保y_pred的值在0和1之间\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "# F1-score\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# 特异性\n",
    "def specificity(y_true, y_pred):\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    specificity = true_negatives / (possible_negatives + K.epsilon())\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设entrIm和entrCat是您的训练图像和标签\n",
    "train_generator = datagen.flow(entrIm, entrCat, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2.compile(optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['acc',precision, recall, f1_score, specificity])\n",
    "#modelo2a = modelo2.fit(x=entrIm, y=entrCat, batch_size=32, epochs=30, verbose=1, validation_data=(testIm, testCat), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2a=modelo2.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(entrIm) / 32,  # 总样本数除以批量大小\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    "    validation_data=(testIm, testCat),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# 在模型训练结束后，使用以下代码计算ROC-AUC和PR AUC\n",
    "y_pred_proba = modelo2.predict(valIm)\n",
    "roc_auc = roc_auc_score(valCat, y_pred_proba)\n",
    "pr_auc = average_precision_score(valCat, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo2.save(\"modF6.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3modelo2.save(\"modF6\", save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. CNN Evaluation\n",
    "Test with validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_eval = modelo2.evaluate(valIm, valCat, verbose=1)\n",
    " \n",
    "print('Validation loss:', test_eval[0])\n",
    "print('Validation accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent how the loss value and acc value change with epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = modelo2a.history['val_loss'] #loss value\n",
    "val_acc = modelo2a.history['val_acc'] #acc value\n",
    "loss = modelo2a.history['loss'] #historical loss array\n",
    "acc = modelo2a.history['acc'] #historical acc array\n",
    "\n",
    "X1a1 = range(1, len(acc)+1)\n",
    "plt.plot(X1a1, acc,'b', label='Training accurarcy')\n",
    "plt.plot(X1a1, val_acc,'r', label='Test accurarcy')\n",
    "plt.title('Training and Test accurarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X1a1, loss, 'b', label='Training loss')\n",
    "plt.plot(X1a1, val_loss, 'r',label='Test loss')\n",
    "plt.title('Training and Test loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制精确率和召回率\n",
    "plt.plot(historia.history['precision'], label='Precision')\n",
    "plt.plot(historia.history['recall'], label='Recall')\n",
    "plt.title('Precision and Recall')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制F1-score和特异性\n",
    "plt.plot(historia.history['f1_score'], label='F1-Score')\n",
    "plt.plot(historia.history['specificity'], label='Specificity')\n",
    "plt.title('F1-Score and Specificity')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Validation and discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values to loss and acc when the model is tested with the validation dataset was:\n",
    "* The Test loss: 0.13231170177459717\n",
    "* Test accuracy: 0.9465737342834473\n",
    "\n",
    "This is a positive result, more than 94 images out of 100 were correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nub_pred = modelo2.predict(valIm, batch_size=32, verbose=1) \n",
    "nub_predicted = np.argmax(nub_pred, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the ROC curve values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(valCat , nub_pred)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1],[0,1],'-')\n",
    "plt.xlabel('Ratio (FPR)')\n",
    "plt.ylabel('Sensibilidad (VPR)')\n",
    "plt.title('Curve ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area of the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC=roc_auc_score ( valCat ,  nub_pred) #Area curva roc\n",
    "print(\"Area of curve ROC=\",AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the result is so positive that the blue line of the ROC curve is close to 1 in the Y axis, which is the maximum possible value. The area of the curve is 0.9832888959371995, a very high and reliable value, the maximum possible value is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other evaluation values for the CNN. In this model the positive case is when it is an image with a cloud and the negative case is when it is an image without a cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = valCat.shape[0]\n",
    "nv = 0; nf = 0; dv= 0; df = 0; na=0\n",
    "cn = 0; cd= 0\n",
    "inf=[]; idf=[]\n",
    "for i in range(dim):\n",
    "    if nub_pred[i] >= 0.5 and valCat[i] == 1:\n",
    "        nv +=1\n",
    "        cn +=1\n",
    "    elif nub_pred[i] >= 0.5 and valCat[i] == 0:\n",
    "        nf +=1\n",
    "        inf.append(valIm[i])\n",
    "        cd +=1\n",
    "    elif nub_pred[i] < 0.5 and valCat[i] == 0:\n",
    "        dv +=1\n",
    "        cd +=1\n",
    "    else :\n",
    "        df +=1\n",
    "        idf.append(valIm[i])\n",
    "        cn +=1\n",
    "    \n",
    "print('True Positive TF=',nv)\n",
    "print('False Positive FP=',nf)\n",
    "print('True Negative TN=',dv)\n",
    "print('False Negative FN=',df)\n",
    "print('Sensitivity VPR=',nv/cn)\n",
    "print('False positive rate FPR=',nf/cd)\n",
    "print('Accuracy  ACC=',(nv+dv)/(cn+cd))\n",
    "print('Specificity SPC=',dv/cd)\n",
    "print('Positive Predictive Value PPV=',nv/(nv+nf))\n",
    "print('Negative Predictive Value NPV=',dv/(dv+df))\n",
    "print('Ratio FDR=',nf/(nf+nv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The lowest values that this CNN has is the Sensitivity VPR= 0.94 versus the Specificity SPC= 0.979655717120500783, which means that this CNN is more efficient detecting images without clouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some images that were not correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "col = 8\n",
    "rows = (len(inf) // col) + (1 if len(inf) % col != 0 else 0)  # Calculate rows based on number of images\n",
    "for i in range(len(inf)):\n",
    "    plt.subplot(rows, col, i + 1)  # Update subplot grid size\n",
    "    plt.imshow(inf[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "col = 8\n",
    "rows = (len(idf) // col) + (1 if len(idf) % col != 0 else 0)  # Calculate rows based on number of images\n",
    "for i in range(len(idf)):\n",
    "    plt.subplot(rows, col, i + 1)  # Update subplot grid size\n",
    "    plt.imshow(idf[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
